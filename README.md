### Table of Contents

1. [Installation](#installation)
2. [Project Motivation](#motivation)
3. [File Descriptions](#files)
4. [Results](#results)
5. [Licensing, Authors, and Acknowledgements](#licensing)

## Installation <a name="installation"></a>

This code uses Python version 3.*.<br/>
The specific libraries required are: 

1. Pyspark
2. Pandas
3. Matplotlib
4. Numpy
5. Seaborn
6. Time
7. Datetime

## Project Motivation<a name="motivation"></a>

This project is the capstone of the Udacity Data Science Nanodegree Programme. I selected the Pyspark option as I was keen to learn more about, and develop experience of using Pyspark which will be important for working with large datasets.


## File Descriptions <a name="files"></a>

1. `Sparkify.ipynb` contains the code for data analysis, wrangling and modeling.
n.b. I could not upload the datafile as it was too big for Github

## Results<a name="results"></a>

The main findings of the code can be found at the post available [here](https://medium.com/@benpreston9/predicting-customer-churn-using-spark-f6b5300597a0).

## Licensing, Authors, Acknowledgements<a name="licensing"></a>

The structure and data for this project was provided by Udacity as part of the Data Scientist Nanodegree.